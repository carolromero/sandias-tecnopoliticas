---
layout: post
title: "The gospel according to Google: the role of technologies and Big Tech in the Palestinian genocide"
date: 2024-01-12 19:00:00 -0400
background: '/img/posts/gospel.jpg'
---
<a href="#cast">Castellano</a>

<p>Digital technologies are being used to wage war, persecute and repress the Palestinian population, and control the narrative on an international scale.</p>

<p>Digital technology is playing an important and dangerous role in the genocide of the Palestinian people. As the Israeli occupation progresses and the siege of the Palestinian population intensifies, the network of technologies, companies and businesses that sponsor and facilitate the massacre also becomes evident. Beyond the war technology that Zionism has always boasted about, on this occasion technology for civilian use also has a determining role. In this article we analyze the use of digital technologies, particularly artificial intelligence systems, in waging war, persecuting, and repressing the Palestinian population, and manipulating the global narrative.</p>

<h2 class="section-heading">Cutting-edge genocide automation technology: Gospel, the AI ​​that selects targets in Gaza.</h2>

<p>An <a href="https://www.972mag.com/mass-assassination-factory-israel-calculated-bombing-gaza/">investigation</a> by the Israeli magazines +972 and Local Call reveals that the Israeli armed forces have been using, since at least 2021, an artificial intelligence system called Habsora (also known as The Gospel). This algorithmic suite is trained and programmed to identify and select bombing targets. It calculates to infer the number of people living or present around a building, likely casualties in an attack. Thus, this calculation makes genocide automation available to the Israel Defense Forces (IDF) and allows them to significantly accelerate the definition of military objectives in the Occupied Palestinian Territories. Officers, the investigation&#39;s sources reveal, compare the &ldquo;productivity&rdquo; of the algorithm with that of a factory. They have gone from being able to achieve 50 objectives a year to identifying 100 a day, of which 50% are attacked. This fact has also meant expanding the bombing campaign to what they call &ldquo;powerful targets&rdquo;: private residences, public buildings and skyscrapers, with the purpose of putting the civilian population to the limit and &ldquo;putting pressure&rdquo; on the Islamic Resistance Movement of Palestine. known as HAMAS.</p>

<p>Investigation sources highlight being asked to &ldquo;look for tall buildings with a floor or space that can be attributed to HAMAS.&rdquo; These sources also recognize this strategy provides&nbsp; an &ldquo;excuse that allows the army to cause a lot of destruction in Gaza.&rdquo; In this way, entire skyscrapers are demolished and civilian families are forced to abandon their homes. Using the pretext of targeting offices and operational spaces of &#39;Islamic Jihad&#39; (which sources consider irrelevant in many cases) what can well be classified as state terrorism is carried out, which remains unpunished in the eyes of the international community. The report also reveals that, in at least one instance, in at least one case, the Israeli military command knowingly approved the bombing of hundreds of Palestinian civilians in an attempt to take out a single senior military command.</p>

<p>The role of artificial intelligence in this entire targeting strategy threatens to blur the responsibility for decisions. <a href="https://www.eldiario.es/internacional/theguardian/evangelio-utiliza-israel-inteligencia-artificial-seleccionar-objetivos-gaza_1_10740704.html">According to Richard Moyes, a researcher at Article 36</a> , when a commander is given a list of computer-generated targets using a system like The Gospel, &ldquo;they don&#39;t have to know what criteria the list was drawn up by, and they can&#39;t ask about the objectives.&rdquo; suggested objectives or question them.&rdquo; Another Israeli expert on the military use of AI, <a href="https://www.middleeasteye.net/news/israel-palestine-war-ai-habsora-random-killing-mathematics">who spoke to MEE on condition of anonymity</a> , said that having a human review every AI-generated target in Gaza is &ldquo;absolutely not feasible.&rdquo; He added that the algorithm does not explain how it reaches its conclusions, making it difficult to verify the validity of an attack&#39;s outcome. &ldquo;No doubt, AI is giving the military an illusion of mathematical precision and analysis, which is false,&rdquo; he said. There is, therefore, the danger that individuals and institutions will begin to depend on these systems and become links in a mechanized process without the capacity to properly assess the risk of harm to civilians. The MEE source adds that &ldquo;all the human defects that the algorithm learned from are automatic there.&rdquo; That is, all the historical injustice, the data and the results of the occupation, colonization and barbarism to which the Palestinian population has been subjected for decades, is codified to optimize and improve military performance, but also to release responsibility. (and internal dissent) to the actions of the IDF.</p>

<p>According to Bianca Baggiarini&#39;s article, <a href="https://asiatimes.com/2023/12/israels-gaza-assault-is-the-future-of-ai-decided-war/">Israel&#39;s Gaza assault is the future of AI-decided war</a> , the boundaries of an AI system that interacts with other technologies and with people may be unclear, and there may be no way <a href="https://www.jstor.org/stable/j.ctv11g97wm">to know who or what has been the &ldquo;author&rdquo;</a> of its results, no matter how objective and rational they may seem. These systems help facilitate <a href="https://arxiv.org/abs/1802.07228">the anonymity</a> of the actors in the war and can make invisible the origin of violence or the decisions that lead to it. We are seeing a growing disconnect between civilian populations, military positions, deployed soldiers, and the wars being fought in the name of the nation they serve.&nbsp;The use of the &#39;Habsora&#39; artificial intelligence system masks random murders with mathematics, say Durgham and Masarwa of the MEE. But it also draws the horizon of the automated future of war conflicts in the era of artificial intelligence.</p>

<h2 class="section-heading">Reaching for the Stars</h2>

<p>As we got further and further away, it [the Earth] diminished in size. Finally it shrank to the size of a marble, the most beautiful you can imagine. That beautiful, warm, living object looked so fragile, so delicate, that if you touched it with a finger it would crumble and fall apart. Seeing this has to change a man.</p>

<img class="img-fluid" src="https://source.unsplash.com/Mn9Fa_wQH-M/800x450" alt="Demo Image">
<span class="caption text-muted">To go places and do things that have never been done before – that’s what living is all about.</span>

<p>Space, the final frontier. These are the voyages of the Starship Enterprise. Its five-year mission: to explore strange new worlds, to seek out new life and new civilizations, to boldly go where no man has gone before.</p>

<p>As I stand out here in the wonders of the unknown at Hadley, I sort of realize there’s a fundamental truth to our nature, Man must explore, and this is exploration at its greatest.</p>

<p>Placeholder text by <a href="http://spaceipsum.com/">Space Ipsum</a>. Photographs by <a href="https://unsplash.com/">Unsplash</a>.</p>
